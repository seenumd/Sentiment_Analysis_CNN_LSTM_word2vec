{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSImsWg8KrtR"
   },
   "source": [
    "Set the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2fynG7CTKrtU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "your_local_path=\"C:/Users/s.mudalapuram/Documents/PythonMe/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u1pImHLPKrth"
   },
   "source": [
    "Data can be downloaded from Kaggle at the following URL\n",
    "\n",
    "- https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dn3NW0Y6Krtf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Change filepath based on where you have stored the data\n",
    "df = pd.read_csv(your_local_path + 'labeledTrainData.zip',header=0, delimiter=\"\\t\", quoting=3)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ycq2gaxWKrt0"
   },
   "source": [
    "Split Data into Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "69AK0WaNKrt6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['review'],\n",
    "    df['sentiment'],\n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "i_djnYMVKruB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vyvYBPHCKruH"
   },
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctHU3z1GNvHR"
   },
   "source": [
    "1.Convert reviews to Number sequences using Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jARgt_VjKruI"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#Vocablury size\n",
    "top_words = 5000\n",
    "t = Tokenizer(num_words=top_words)\n",
    "\n",
    "#Fit tokenizer of training data\n",
    "t.fit_on_texts(X_train.tolist())\n",
    "\n",
    "#Get the word index for each of the word in the review\n",
    "X_train = t.texts_to_sequences(X_train.tolist())\n",
    "X_test = t.texts_to_sequences(X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7Q04H7mZKrum"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of review# 32 is:  317\n",
      "Length of review# 1208 is:  117\n"
     ]
    }
   ],
   "source": [
    "#Length of different reviews is different\n",
    "print('Length of review# 32 is: ', len(X_train[32]))\n",
    "print('Length of review# 1208 is: ', len(X_train[1208]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SW1w9vpPOuSP"
   },
   "source": [
    "2.Pad the sequences - to make every review equal in size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HM_scpolKru5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "\n",
    "#Length for each review\n",
    "max_review_length = 300\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train,maxlen=max_review_length,\n",
    "                                 padding='post')\n",
    "\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length, \n",
    "                                padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dv8ShIfuKru8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of review# 32 is:  300\n",
      "Length of review# 1208 is:  300\n"
     ]
    }
   ],
   "source": [
    "#Length of different reviews should be SAME now\n",
    "print('Length of review# 32 is: ', len(X_train[32]))\n",
    "print('Length of review# 1208 is: ', len(X_train[1208]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "O10S28KkrJRd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  11,   17,    6,    3,  977,    3,   62,    4,    3,  183,  251,\n",
       "        311,    1,  317,    2,    9,   63,  585,   21,  622,   14,    1,\n",
       "         17,   18,    9,    6,    3,   82,   62,   10,   13, 4142,   31,\n",
       "         11,   19,    1,  112,    2,    1,   62,  117,   82,   10,   37,\n",
       "         11,   19,   85,    9,    6,    3,  278,   62,   42,   68,    3,\n",
       "        543,   12,   10,   13,   46,    2,   10,  229,  788,   15,    1,\n",
       "         12,    6,  396,   85,   34,  485,    5,  127,  130,  111,   12,\n",
       "         94,   10,  383,   12, 1441,   25,    5,   64,   11,   19,  318,\n",
       "          1,  183,  657,    2,   31,    1,  845,  138,   36,   11,   19,\n",
       "         11,   19,   22,   67, 1631,    1,   17, 1689,   36, 4960,   39,\n",
       "         98,  143,   62,   12,  563,    8,    1,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1208]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LGWNKBknKrvY"
   },
   "source": [
    "## Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6ei6Eg4YKrva"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Dense, Embedding, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cc6h4mP5P7FZ"
   },
   "outputs": [],
   "source": [
    "# Define how many numbers per word for Word embeddings\n",
    "embedding_vector_length = 50 \n",
    "\n",
    "#Build a model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VToUG0wfKrvv"
   },
   "source": [
    "Add Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SFJjSzakKrvx"
   },
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Embedding(top_words+1, #Vocablury Size, why +1\n",
    "                    embedding_vector_length, #How many numbers per word\n",
    "                    input_length=max_review_length) #Words in each review\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iSy7vWpBKrv1"
   },
   "source": [
    "Output from Embedding is 3 dimension \n",
    "- batch_size x max_review_length x embedding_vector_length. \n",
    "\n",
    "We need to flatten the output for Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nKdEVQdxKrv2"
   },
   "outputs": [],
   "source": [
    "#Flatten the input\n",
    "model.add(Flatten())\n",
    "\n",
    "#Dense Layers\n",
    "model.add(Dense(200,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(60,activation='relu'))\n",
    "model.add(Dense(30,activation='relu'))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "deqoDS9uKrwQ"
   },
   "source": [
    "## Execute the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rUG6_UwnKrwQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 63s 3ms/step - loss: 0.6599 - acc: 0.6063 - val_loss: 0.6641 - val_acc: 0.5828\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 65s 3ms/step - loss: 0.4744 - acc: 0.7736 - val_loss: 0.3867 - val_acc: 0.8320\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 63s 3ms/step - loss: 0.3191 - acc: 0.8632 - val_loss: 0.5886 - val_acc: 0.7368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x196cd067278>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change number of epochs appropriately\n",
    "model.fit(X_train,y_train,\n",
    "          epochs=3,\n",
    "          batch_size=128,\n",
    "          shuffle=True, \n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MeRoaAu312GK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05418413],\n",
       "       [0.9932783 ],\n",
       "       [0.35033822],\n",
       "       [0.991521  ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "1b. Sentiment_Analysis_Embedding_FC_Layer.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
